
# Installation des bibliothÃ¨ques nÃ©cessaires
!pip install tensorflow keras numpy matplotlib seaborn
!apt install unzip

import zipfile

# DÃ©finition des chemins pour l'extraction des donnÃ©es
dataset_zip_path = "/content/dataset.zip"  # Remplace par le chemin de ton fichier
dataset_extract_path = "/content/dataset"

# Extraction du dataset
with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:
    zip_ref.extractall(dataset_extract_path)

print("ğŸ“‚ Dataset extrait avec succÃ¨s !")

# ğŸ“Œ Importation des bibliothÃ¨ques
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“‚ DÃ©finition des chemins des jeux de donnÃ©es
train_dir = "/content/dataset/train"
test_dir = "/content/dataset/test"

# âš™ï¸ PrÃ©paration des donnÃ©es avec Data Augmentation
datagen = ImageDataGenerator(
    rescale=1./255,  # Normalisation des pixels
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% des donnÃ©es utilisÃ©es pour la validation
)

# ğŸ“¥ Chargement des donnÃ©es avec le gÃ©nÃ©rateur
batch_size = 32
img_size = (48, 48)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

num_classes = len(train_generator.class_indices)
print("ğŸ”¢ Nombre de classes :", num_classes)

# ğŸ“Œ Construction du modÃ¨le avec VGG16 (Transfer Learning)

# ğŸ”¥ Chargement du modÃ¨le prÃ©-entraÃ®nÃ© VGG16 sans la derniÃ¨re couche
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))

# ğŸ”’ Geler les poids du modÃ¨le prÃ©-entraÃ®nÃ©
for layer in base_model.layers:
    layer.trainable = False

# ğŸ“Œ DÃ©finition du modÃ¨le personnalisÃ©
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')  # Classification multi-classes
])

# ğŸ”§ Compilation du modÃ¨le
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# ğŸ” Affichage de l'architecture du modÃ¨le
model.summary()

# ğŸ“Œ EntraÃ®nement du modÃ¨le
epochs = 30

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=epochs,
    steps_per_epoch=len(train_generator),
    validation_steps=len(val_generator)
)

# ğŸ“Œ Ã‰valuation du modÃ¨le sur les donnÃ©es de test
test_loss, test_acc = model.evaluate(test_generator)
print(f"ğŸ¯ PrÃ©cision sur le test: {test_acc:.2f}")

# ğŸ“Œ Sauvegarde et tÃ©lÃ©chargement du modÃ¨le
model.save("emotion_model.h5")
from google.colab import files
files.download("emotion_model.h5")

# ğŸ“Œ Utilisation du modÃ¨le sauvegardÃ© sur VS Code
# Installation de TensorFlow si nÃ©cessaire
!pip install tensorflow keras numpy matplotlib

# Chargement du modÃ¨le entraÃ®nÃ©
from tensorflow.keras.models import load_model
model = load_model("emotion_model.h5")

# ğŸ“Œ PrÃ©diction sur une image d'entrÃ©e
import cv2
img = cv2.imread("image_a_predire.jpg")
img = cv2.resize(img, (48, 48))
img = img / 255.0
img = np.expand_dims(img, axis=0)

prediction = model.predict(img)
print("Ã‰motion prÃ©dite :", np.argmax(prediction))
