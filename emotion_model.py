

# Installation des biblioth√®ques n√©cessaires
!pip install tensorflow keras numpy matplotlib seaborn
!apt install unzip

import zipfile

# D√©finition des chemins pour l'extraction des donn√©es
dataset_zip_path = "/content/dataset.zip"  # Remplace par le chemin de ton fichier
dataset_extract_path = "/content/dataset"

# Extraction du dataset
with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:
    zip_ref.extractall(dataset_extract_path)

print("Dataset extrait avec succ√®s !")

# Importation des biblioth√®ques
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import seaborn as sns

# D√©finition des chemins des jeux de donn√©es
train_dir = "/content/dataset/train"
test_dir = "/content/dataset/test"

# Pr√©paration des donn√©es avec Data Augmentation
datagen = ImageDataGenerator(
    rescale=1./255,  # Normalisation des pixels
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% des donn√©es utilis√©es pour la validation
)

# Chargement des donn√©es avec le g√©n√©rateur
batch_size = 32
img_size = (48, 48)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

num_classes = len(train_generator.class_indices)
print(" Nombre de classes :", num_classes)

# Construction du mod√®le avec VGG16 (Transfer Learning)

# Chargement du mod√®le pr√©-entra√Æn√© VGG16 sans la derni√®re couche
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))

#  Geler les poids du mod√®le pr√©-entra√Æn√©
for layer in base_model.layers:
    layer.trainable = False

# D√©finition du mod√®le personnalis√©
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')  # Classification multi-classes
])

# üîß Compilation du mod√®le
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#  Affichage de l'architecture du mod√®le
model.summary()

#  Entra√Ænement du mod√®le
epochs = 30

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=epochs,
    steps_per_epoch=len(train_generator),
    validation_steps=len(val_generator)
)

#  √âvaluation du mod√®le sur les donn√©es de test
test_loss, test_acc = model.evaluate(test_generator)
print(f"üéØ Pr√©cision sur le test: {test_acc:.2f}")

# Sauvegarde et t√©l√©chargement du mod√®le
model.save("emotion_model.h5")
from google.colab import files
files.download("emotion_model.h5")

# Utilisation du mod√®le sauvegard√© sur VS Code
# Installation de TensorFlow si n√©cessaire
!pip install tensorflow keras numpy matplotlib

# Chargement du mod√®le entra√Æn√©
from tensorflow.keras.models import load_model
model = load_model("emotion_model.h5")

#  Pr√©diction sur une image d'entr√©e
import cv2
img = cv2.imread("image_a_predire.jpg")
img = cv2.resize(img, (48, 48))
img = img / 255.0
img = np.expand_dims(img, axis=0)

prediction = model.predict(img)
print("√âmotion pr√©dite :", np.argmax(prediction))
